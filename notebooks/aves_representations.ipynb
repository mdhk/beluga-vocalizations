{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a49419-74df-4932-a3b0-c5f732dd79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beluga_vocalizations.paths import (\n",
    "    ROOT, \n",
    "    BELUGA_AUDIO,\n",
    "    AVES_BIO_CONFIG, \n",
    "    AVES_BIO_MODEL\n",
    ")\n",
    "from beluga_vocalizations.data_loading import load_recordings_df, get_dataloader\n",
    "from beluga_vocalizations.model_loading import AvesEmbedding\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6f7c04-2587-499a-a20f-5a122ffe0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = load_recordings_df(ROOT / 'results/recordings.csv').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88cddc7-fcf2-4503-ad67-f5e25936cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = AvesEmbedding(config_path=AVES_BIO_CONFIG,\n",
    "                                model_path=AVES_BIO_MODEL)\n",
    "embedding_model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    embedding_model.cuda()\n",
    "\n",
    "dl = get_dataloader(rec_df, embedding_model.audio_sr, [\"voc_idx\", \"call_class\", \"call_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303b05d3-56f4-4bed-afd7-3e478dba7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_idx = []\n",
    "emb_idx = []\n",
    "embeddings = []\n",
    "for rec in dl:\n",
    "    x = rec['x'].cuda()\n",
    "    voc = rec['voc_idx'].item()\n",
    "    with torch.no_grad():\n",
    "        out = embedding_model(x).cpu().detach().numpy()\n",
    "    N_frames = out.shape[1]\n",
    "    start_times = np.arange(0, embedding_model.frame_len*(N_frames+1), embedding_model.frame_len)[:N_frames]\n",
    "    voc_idx.extend([voc]*N_frames)\n",
    "    emb_idx.extend([str(voc).zfill(4) + '_' + \"{:.2f}\".format(st) for st in start_times])\n",
    "    embeddings.extend([out[:, i, :].squeeze() for i in range(N_frames)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e30628e-bcc5-43da-b21c-51d3ea5134c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = pd.DataFrame(np.vstack(embeddings), \n",
    "                      columns=[f'emb{d+1}' for d in range(embedding_model.emb_dim)])\n",
    "emb_df.insert(0, 'emb_idx', emb_idx)\n",
    "emb_df.insert(1, 'voc_idx', voc_idx)\n",
    "emb_df = emb_df.set_index('emb_idx')\n",
    "emb_df.to_csv(ROOT / 'results/AVES_frame_embeddings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beluga-env",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
